{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_Raining_RandomForestClassifier.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPQgaTy6l6QK+zRy6S5V6/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WoradeeKongthong/raining_tomorrow_classification/blob/master/08_Raining_RandomForestClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzAQNizAP0nG",
        "colab_type": "text"
      },
      "source": [
        "Based on Feature Engineering in part 02  \n",
        "Outliers : I'll cap the outliers in X_train. And cap the outliers in X_test using the boundaries of X_train.  \n",
        "Missing values : I'll impute the missing values in categorical features with 'most frequent' value,  \n",
        "and impute the missing values in numerical features with median."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyn_b_XCxRkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbQH-UK5xWlL",
        "colab_type": "text"
      },
      "source": [
        "# **Data Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF6DT6FQxUxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/WoradeeKongthong/raining_tomorrow_classification/master/weatherAUS.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPNHKHJ7xeWT",
        "colab_type": "code",
        "outputId": "ab0edeb0-0f8c-426a-87ed-2fe89920e0bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 142193 entries, 0 to 142192\n",
            "Data columns (total 24 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   Date           142193 non-null  object \n",
            " 1   Location       142193 non-null  object \n",
            " 2   MinTemp        141556 non-null  float64\n",
            " 3   MaxTemp        141871 non-null  float64\n",
            " 4   Rainfall       140787 non-null  float64\n",
            " 5   Evaporation    81350 non-null   float64\n",
            " 6   Sunshine       74377 non-null   float64\n",
            " 7   WindGustDir    132863 non-null  object \n",
            " 8   WindGustSpeed  132923 non-null  float64\n",
            " 9   WindDir9am     132180 non-null  object \n",
            " 10  WindDir3pm     138415 non-null  object \n",
            " 11  WindSpeed9am   140845 non-null  float64\n",
            " 12  WindSpeed3pm   139563 non-null  float64\n",
            " 13  Humidity9am    140419 non-null  float64\n",
            " 14  Humidity3pm    138583 non-null  float64\n",
            " 15  Pressure9am    128179 non-null  float64\n",
            " 16  Pressure3pm    128212 non-null  float64\n",
            " 17  Cloud9am       88536 non-null   float64\n",
            " 18  Cloud3pm       85099 non-null   float64\n",
            " 19  Temp9am        141289 non-null  float64\n",
            " 20  Temp3pm        139467 non-null  float64\n",
            " 21  RainToday      140787 non-null  object \n",
            " 22  RISK_MM        142193 non-null  float64\n",
            " 23  RainTomorrow   142193 non-null  object \n",
            "dtypes: float64(17), object(7)\n",
            "memory usage: 26.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj7iJFs5yR4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop RISK_MM column (Recommendation from data description in Kaggle)\n",
        "df.drop(['RISK_MM'], axis = 1, inplace = True)\n",
        "\n",
        "# Extract Year, Month, Day from Date column\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Day'] = df['Date'].dt.day\n",
        "\n",
        "# drop Date column\n",
        "df.drop(['Date'], axis = 1, inplace = True)\n",
        "\n",
        "# select year 2015-2017 to train the model\n",
        "df = df[df['Year'] > 2014]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wib900L2yWUs",
        "colab_type": "code",
        "outputId": "6dd1948c-3e18-44b4-88fb-e89c0f535d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 43205 entries, 2109 to 142192\n",
            "Data columns (total 25 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Location       43205 non-null  object \n",
            " 1   MinTemp        43002 non-null  float64\n",
            " 2   MaxTemp        43081 non-null  float64\n",
            " 3   Rainfall       42799 non-null  float64\n",
            " 4   Evaporation    19472 non-null  float64\n",
            " 5   Sunshine       16085 non-null  float64\n",
            " 6   WindGustDir    40818 non-null  object \n",
            " 7   WindGustSpeed  40837 non-null  float64\n",
            " 8   WindDir9am     40515 non-null  object \n",
            " 9   WindDir3pm     41457 non-null  object \n",
            " 10  WindSpeed9am   42990 non-null  float64\n",
            " 11  WindSpeed3pm   41715 non-null  float64\n",
            " 12  Humidity9am    42696 non-null  float64\n",
            " 13  Humidity3pm    40781 non-null  float64\n",
            " 14  Pressure9am    38536 non-null  float64\n",
            " 15  Pressure3pm    38533 non-null  float64\n",
            " 16  Cloud9am       25312 non-null  float64\n",
            " 17  Cloud3pm       22877 non-null  float64\n",
            " 18  Temp9am        43084 non-null  float64\n",
            " 19  Temp3pm        41142 non-null  float64\n",
            " 20  RainToday      42799 non-null  object \n",
            " 21  RainTomorrow   43205 non-null  object \n",
            " 22  Year           43205 non-null  int64  \n",
            " 23  Month          43205 non-null  int64  \n",
            " 24  Day            43205 non-null  int64  \n",
            "dtypes: float64(16), int64(3), object(6)\n",
            "memory usage: 8.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyVUietnBKdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(['RainTomorrow'], axis=1)\n",
        "y = df['RainTomorrow']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i2T_KdUJl_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eld7lLTwHqIb"
      },
      "source": [
        "# **Handle the Outliers**\n",
        "Training Set\n",
        "- cap the outliers in X_train\n",
        "\n",
        "Test Set\n",
        "- cap the outliers in X_test using the upper_cap and lower_cap of X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W10238cQdgk_",
        "colab_type": "text"
      },
      "source": [
        "## **Cap the outlier in X_train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LhH5ybtJea9k",
        "outputId": "d175d832-d170-45c3-d624-1ed71dc63cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "Q1 = X_train.quantile(0.25)\n",
        "Q3 = X_train.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_cap = Q1 - 1.5*IQR\n",
        "upper_cap = Q3 + 1.5*IQR\n",
        "\n",
        "features = lower_cap.index.values\n",
        "\n",
        "for feature in features :\n",
        "  X_train.loc[:,feature] = np.where(X_train.loc[:,feature]<lower_cap[feature],lower_cap[feature], X_train.loc[:,feature])\n",
        "  X_train.loc[:,feature] = np.where(X_train.loc[:,feature]>upper_cap[feature],upper_cap[feature], X_train.loc[:,feature])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuEdINujegSA",
        "colab_type": "text"
      },
      "source": [
        "## **Cap the outlier in X_test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2-2YEbQcea9p",
        "outputId": "addd9446-db85-43de-9289-6193b862af16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "for feature in features :\n",
        "  X_test.loc[:,feature] = np.where(X_test.loc[:,feature]<lower_cap[feature],lower_cap[feature], X_test.loc[:,feature])\n",
        "  X_test.loc[:,feature] = np.where(X_test.loc[:,feature]>upper_cap[feature],upper_cap[feature], X_test.loc[:,feature])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7a_bLnRZz7O",
        "colab_type": "text"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8gTLxR-CR9G",
        "colab_type": "text"
      },
      "source": [
        "**Create Preprocessor : ColumnTransformer of numerical and categorical features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTT3lZG8Cxg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numerical_features = [x for x in X.columns if df[x].dtype != 'object']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "          ('imputer', SimpleImputer(strategy='median')),\n",
        "          ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_features = [x for x in X.columns if df[x].dtype == 'object']\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "          ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "          ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "          ('num', numeric_transformer, numerical_features),\n",
        "          ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPVvzPIUSbfy",
        "colab_type": "text"
      },
      "source": [
        "**Create model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMg6-FaGSQj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY_lpfneSrHi",
        "colab_type": "text"
      },
      "source": [
        "**Create Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJOsYV7mSqkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = Pipeline(steps=[\n",
        "      ('preprocessor', preprocessor),\n",
        "      ('model', model)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehj5f2TlfFVh",
        "colab_type": "text"
      },
      "source": [
        "# **Model Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r8Sj1iG9Ko0q"
      },
      "source": [
        "## **Cross Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "befd63f8-38ee-4b8d-feb0-dd439a0ea55d",
        "id": "a19IDMNwKo0t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "accuracy = cross_val_score(clf,X_train,y_train,cv=10)\n",
        "print('accuracy : ', accuracy)\n",
        "print('mean : ', accuracy.mean())\n",
        "print('std : ', accuracy.std())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy :  [0.84119178 0.83714203 0.83540642 0.84061325 0.84751157 0.83072917\n",
            " 0.83072917 0.83738426 0.83969907 0.8365162 ]\n",
            "mean :  0.8376922930125671\n",
            "std :  0.004745526295881819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uuBDr_guKo0x"
      },
      "source": [
        "Note : low bias and low variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DOpQv9dQKo0x"
      },
      "source": [
        "## **Training and Test evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "33544919-292e-4395-b494-8b38d56d3437",
        "id": "WmaZx-SOKo0y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print('\\n\\nTraining and Test Sets result')\n",
        "print('\\naccuracy score : ', accuracy_score(y_test,y_pred))\n",
        "print('\\nconfusion matrix : \\n', confusion_matrix(y_test, y_pred))\n",
        "print('\\nclassification report : \\n', classification_report(y_test,y_pred))\n",
        "\n",
        "print('Training set score : ',clf.score(X_train,y_train))\n",
        "print('Test set score : ',clf.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training and Test Sets result\n",
            "\n",
            "accuracy score :  0.8335840759171392\n",
            "\n",
            "confusion matrix : \n",
            " [[6382  326]\n",
            " [1112  821]]\n",
            "\n",
            "classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          No       0.85      0.95      0.90      6708\n",
            "         Yes       0.72      0.42      0.53      1933\n",
            "\n",
            "    accuracy                           0.83      8641\n",
            "   macro avg       0.78      0.69      0.72      8641\n",
            "weighted avg       0.82      0.83      0.82      8641\n",
            "\n",
            "Training set score :  0.9865177641476681\n",
            "Test set score :  0.8335840759171392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QjGBwLn3Ko02"
      },
      "source": [
        "Note : slightly overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpdZD7kll7O9",
        "colab_type": "text"
      },
      "source": [
        "# **Improve the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0RY7WAtB3J_",
        "colab_type": "text"
      },
      "source": [
        "## add max_depth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Cx8aACCI-9",
        "colab_type": "code",
        "outputId": "b9111bab-53d8-4968-975f-4e1e09b96e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "for i in [5,6,7,8,9,10]:\n",
        "  model = RandomForestClassifier(n_estimators = 10, max_depth = i, criterion = 'entropy')\n",
        "  clf = Pipeline(steps=[\n",
        "      ('preprocessor', preprocessor),\n",
        "      ('model', model)\n",
        "  ])\n",
        "\n",
        "  clf.fit(X_train,y_train)\n",
        "\n",
        "  print('Random Forest : max_depth = {}'.format(i))\n",
        "  print('Training set score : ',clf.score(X_train,y_train))\n",
        "  print('Test set score : ',clf.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest : max_depth = 5\n",
            "Training set score :  0.8189445666010878\n",
            "Test set score :  0.8093970605254022\n",
            "Random Forest : max_depth = 6\n",
            "Training set score :  0.8310380742969564\n",
            "Test set score :  0.8234000694364079\n",
            "Random Forest : max_depth = 7\n",
            "Training set score :  0.8331790302048374\n",
            "Test set score :  0.8212012498553408\n",
            "Random Forest : max_depth = 8\n",
            "Training set score :  0.8387050109940979\n",
            "Test set score :  0.8266404351348223\n",
            "Random Forest : max_depth = 9\n",
            "Training set score :  0.8464008795278324\n",
            "Test set score :  0.825135979631987\n",
            "Random Forest : max_depth = 10\n",
            "Training set score :  0.8536338386760791\n",
            "Test set score :  0.8306908922578405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzhD7TMgELgH",
        "colab_type": "text"
      },
      "source": [
        "Note : max_depth helps reduce overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD_fLcBHppWk",
        "colab_type": "text"
      },
      "source": [
        "## GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9vMSJNhpo22",
        "colab_type": "code",
        "outputId": "d5f25862-da6f-4ebb-abca-971480422306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=10, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so0yfuiUpxeS",
        "colab_type": "code",
        "outputId": "b9d6dedc-7b8f-48bc-9384-928c5155ca6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'model__max_depth':[8],\n",
        "    'model__n_estimators':[10,20,30,40,50],\n",
        "}\n",
        "\n",
        "search = GridSearchCV(clf, param_grid, n_jobs=-1)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameter : \", search.best_params_)\n",
        "print(\"Best score : \", search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameter :  {'model__max_depth': 8, 'model__n_estimators': 50}\n",
            "Best score :  0.831964054070163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZHHEPpz1AdT",
        "colab_type": "code",
        "outputId": "a806a52f-d33b-4f9f-9f55-77581e76afa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# train-test on the best parameter\n",
        "\n",
        "model = RandomForestClassifier(n_estimators = 50,max_depth = 8, criterion='entropy')\n",
        "\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print('\\n\\nTraining and Test Sets result')\n",
        "print('\\naccuracy score : ', accuracy_score(y_test,y_pred))\n",
        "print('\\nconfusion matrix : \\n', confusion_matrix(y_test, y_pred))\n",
        "print('\\nclassification report : \\n', classification_report(y_test,y_pred))\n",
        "\n",
        "print('Training set score : ',clf.score(X_train,y_train))\n",
        "print('Test set score : ',clf.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training and Test Sets result\n",
            "\n",
            "accuracy score :  0.829649346140493\n",
            "\n",
            "confusion matrix : \n",
            " [[6531  177]\n",
            " [1295  638]]\n",
            "\n",
            "classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          No       0.83      0.97      0.90      6708\n",
            "         Yes       0.78      0.33      0.46      1933\n",
            "\n",
            "    accuracy                           0.83      8641\n",
            "   macro avg       0.81      0.65      0.68      8641\n",
            "weighted avg       0.82      0.83      0.80      8641\n",
            "\n",
            "Training set score :  0.8432183775026039\n",
            "Test set score :  0.829649346140493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfc6vDps2PHc",
        "colab_type": "text"
      },
      "source": [
        "Note : Overfitting is reduced"
      ]
    }
  ]
}